\section{Evaluation}
\label{sec:evaluation}

In this section, we first give out some comparisons on accuracy. Then show the performance improvement of local feature descriptor by using {\sys}, an evaluation is also performed on {\sys} combined with SIFT and SURF, which are most widely used {\lfea}s. For SIFT, we use an open-source version provided by Rob Hess~\cite{hess2010opensift} as the baseline. For SURF, we also choose an open-source implementation, OpenSURF~\cite{evans2009notes}.

Two data sets are used to satisfy different evaluation purposes.  The first one is a data set of 1000 $640\times480$ images with labeled salient regions by Achanta et at.~\cite{achanta2009frequency}, which is used to evaluate the detection accuracy of salient regions. The second one is a much larger image database provided by Nist~\cite{nister2006scalable}, which consists of 10200 $640\times480$ images for image retrieval system.

The evaluations are performed on a 4-core server with 4GB memory. Each processor is an Intel Core i7 CPU with 3.4Ghz frequency. All the algorithms are compiled by GCC 4.4.0 with optimization argument -O2 under Fedora 11.



\subsection{Experimental Comparison}
\label{sec:evaluation_comparison}

The major motivation of this paper is to design an algorithm for local feature reduction using salient region. To achieve this goal, an approximate salient region detection algorithm is designed. Although our approach cannot detect precise salient region, we are still interested in evaluating its precision against general purpose ones. Here we compare {\sys} with GBSR (Global Contrast based Salient Region)~\cite{cheng2011global}. GBSR is a state-of-the-art salient region detection algorithm, which can achieve the best precision and recall rate compared with prior salient region algorithms. Moreover, it is more efficent than other salient regions detection algorithm. The processing time of GBSR includes two parts: the saliency map detection and its segmentation.

Since we only focus on {\lfea}s, our precision and recall evaluation differs from regular salient region researches a little. As input, we first generate both SURF and SIFT local features for the whole data set. Then we collect the feature points in the salient regions calculated by the ground truth (the regions labelled by Achanta et al. by hand), GBSR and {\sys}. At last, the GBSR's and {\sys}'s precision and recall are calculated based on their results compared with that of the ground truth. In other words, only the local features computed by the ground truth are considered as the truly salient features and the others are false features. Thus, the precision and recall equations are defined as follows.

{\begin{equation} \label{eq:precision}
Precision = \frac{{N}_{correct}}{{n}_{detected}}
\end{equation}}

{\begin{equation} \label{eq:recall}
Recall = \frac{{N}_{correct}}{{N}_{true}}
\end{equation}}

Where ${N}_{correct}$ refers to the number of local features located in both the ground truth and GBSR or {\sys}. ${N}_{detected}$ in equation~\ref{eq:precision} refers to the total number of local features detected by GBSR or {\sys}, while ${N}_{true}$ in equation~\ref{eq:recall} is the number of truly salient features in the ground truth.

\begin{table}[!ht]
\begin{center}
\begin{tabular}{|l|c|c|c|c|c|}
\hline
 & P & R & RE & SM(ms) & SG(ms) \\
\hline
GBSR   & 0.81 & 0.86 & 39\% &180 & 2080 \\
{\sys} & 0.52 & 0.59  & 42\% & N/A & 3 \\
\hline
\end{tabular}
\end{center}
\caption{Comparison between GBSR and {\sys} in precision (P), recall (R), reduction efficiency, saliency map (SM) and segmentation (SG) processing time in milliseconds.}
\label{tab:comparison}
\end{table}

The comparison result is presented in Table~\ref{tab:comparison}. As shown in the column 2 and 3, {\sys} gets lower precision rate and lower recall rate compared to GBSR. The major reason is that our algorithm is an approximate design, which focuses on fast processing speed and accurate retrieval instead of precise boundaries of salient regions. The reduction efficiency in the column 4 refers to the proportion of the left local features after a reduction. The results shows that both of them can help to eliminate more than half of the original features. GBSR achieves a higher reduction rate due to its precise boundary detection.

The result in the column 5 and 6 of Table~\ref{tab:comparison} presents the efficiency comparison, It shows that the well optimized GBSR costs average 2086 milliseconds to get the final salient region for an image, while {\sys} only costs 3.2 milliseconds. Even only counting the time for saliency map detection, GBSR still needs average 178 milliseconds. The performance result of {\sys} is very impressive because the computation of {\sys} is really simple and straightforward.


%-----------------------------------------------------------------------------------------
%-----------------------------------------------------------------------------------------
\subsection{Combination into Retrieval Systems}
\label{sec:evaluation_integration}



{\sys} is designed to improve the performance of {\lfea}s. To verify whether {\sys} satisfies this design purpose, we also evaluate the retrieval accuracy of {\sys} and GBSR. We implement a whole image retrieval system for evaluation. The system first builds a VOC-Tree~\cite{nister2006scalable} by using the feature points extracted by SIFT or SURF from image data sets. Then, each incoming query image is transferred into feature vectors too and retrieved in that VOC-Tree. At last, the found top similar images would be reordered by using RANSAC~\cite{fischler1981random}. In the evaluated data set, four similar images, which are taken from different perspectives for one object, are organized into one group, and for all 10200 images, there are 2550 image groups. When using one image to retrieve, the score of this retrieval is how many images in the same group are found in the top four results. For example, getting three similar images of the query one in the top four retrieval results means a score of 3 and getting nothing similar means a score of 0.

\begin{figure*}[!ht]
\centering
\includegraphics[width=4.5in]{images/fig-gbsr.eps}
\caption{Example feature reduction results conducted by GBSR. From left to right, the first column lists original images, the second column presents binary masks detected by GBSR, and the third column are the local feature reduction result conducted by GBSR, where green points are salient features and red points are filtered ones.}
\label{fig:gbsr}
\end{figure*}

To integrate with salient region algorithm, we replace the original {\lfea} with a salient region conducted version in the image retrieval system. When using an integrated system, the VOC-tree is built based on the feature points in the detected salient regions. Moreover, the retrieval is also based on the feature points in the detected salient regions of a query image.

\begin{table}[!ht]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\multicolumn{2}{|c|}{} & Query Time & Accuracy \\
\hline
\multirow{3}{*}{SURF} & Original & 0.49s & - \\
& {\sys} &  0.31s & 94\% \\
& GBSR & 2.35s & 93\% \\
\hline
\multirow{3}{*}{SIFT} & Original & 1.5s & - \\
& {\sys} & 0.72s & 93\% \\
& GBSR & 2.58s & 85\% \\
\hline
\end{tabular}
\end{center}
\caption{Comparison between original {\lfea}, {\sys} and GBSR conducted algorithms in a realistic image retrieval system. Query time includes salient region detection and feature detection time, VOC-Tree query time and RANSAC time for the whole image retrieval system. Accuracy refers to the accuracy of the {\sys} and GBSR conducted retrieval system compared to the original ones.}
\label{tab:integration}
\end{table}

Table~\ref{tab:integration} shows the performance results. By reducing local features, the {\sys} conducted image retrieval system gains more than 1.6X speedup for one image query. Although GBSR version has a better reduction efficiency as discussed in the Section~\ref{sec:evaluation_comparison}, the query time becomes worse due to GBSR's long processing time, which leads to longer feature extraction time.

We also present the accuracy influence by introducing {\sys} and GBSR to the retrieval system. In the evaluated data set, four similar images are organized into one group, and for all 10200 images, there are 2550 image groups. For each image retrieval, the score of this retrieval is how many images in the same group are found in the top four results. For example, getting three similar images of the query one in the top four retrieval results means a score of 3 and getting nothing similar means a score of 0.

As shown in the fourth column of Table~\ref{tab:integration}, we get the accuracy by dividing the score of {\sys} and GBSR based algorithms by the score of the original ones. {\sys} based algorithms show a 7\% precision loss. In contrast, GBSR based algorithm shows a more obvious precision loss. When combined with SIFT, the accuracy loss is about 15\%. The major reason behind such a result is that GBSR is a precise silent region detection algorithm. When it used to reduce the feature points in a local feature-based retrieval system, only the points in its detection regions are remained. However, in {\lfea}s, many important points locate in the boundary of an object. To illustrate it clearer, we also give an example shown in Figure~\ref{fig:gbsr}. As the right column shown, many important feature points in the boundary are discarded after GBSR is used, which leads to a larger accuracy loss.
