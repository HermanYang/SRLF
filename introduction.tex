\section{Introduction}
\label{sec:introduction}

Our society has entered a data-centric era with a huge amount of data being transferred and processed on the Internet. Among them, multimedia data, such as image and video, has become one of the major data types. As analyzed by CISCO Inc., video data occupies 50\% of network traffic in 2011 and will increase to more than 90\% in 2013~\cite{index2010forecast}. According to a report~\cite{jansohn2009detecting}, as one of the most popular video sharing sites, more than 60-hour new videos are uploaded to \emph{YouTube} every minute. Moreover, \emph{Facebook} and \emph{Flickr} have hosted billions of user-uploaded photos.

With the rapid increase of multimedia data, one of the most significant challenges is to understand and interpret such a huge amount of multimedia data. Currently, more and more retrieval applications are emerging to process these multimedia data, such as video recommendation~\cite{yang2007online}, travel guidance~\cite{gao2010w2go} and content-based TV copy identification~\cite{joly2003robust}.

Based on feature types, these multimedia retrieval systems can mainly be classified into two categories: global feature-based and local feature-based. Global feature-based algorithms tend to describe an image\footnote{Since video retrieval applications also use image retrieval algorithms to extract the features for their frames, these applications will be considered as special image retrieval applications in the following parts of this paper.} as a whole, such as contour representations, shape descriptors and texture features. Although global feature-based algorithms can achieve a high processing speed, their accuracy cannot be guaranteed. On the other hand, {\lfea}s represent  an image with hundreds of high-dimensional feature points, such as SIFT~\cite{lowe1999object,lowe2004distinctive} and SURF~\cite{bay2006surf,evans2009notes}.

Compared to global feature-based algorithms, {\lfea}s are more robust, both scale-invariant and rotation-invariant~\cite{mikolajczyk2005performance}\cite{bauer2007comparing} are guranteed but not the processing speed. Even the SURF algorithm, an optimized algorithm derived from SIFT, is still very slow. While executed on a 3.3GHz Core i7 CPU~\cite{chen2012adaptive}, it can only achieve a processing speed of less than five frames per second, far from the real-time requirement. Moreover, since extracting hundreds of high-dimensional feature points for each image, it generally requires several hundred KB storage space to save the feature points of an image. With a dramatically increasing of image or video amount on the Internet, it puts a great pressure on real-time processing and large-scale data storage.

In general, a {\lfea} consists of two stages: feature detection stage and feature description stage. In feature detection stage, feature points in an image are located. And in the description stage, each point is described into a high-dimensional vector based on the information around it. As analyzed in \cite{chen2012adaptive}, description stage is much more time-consuming.In an image or a video frame, there exist some human visual attention regions, which called salient regions. If only the feature points in salient regions are extracted, the image can be still be represented well and the storage pressure can be released. There have been many salient region detection techniques~\cite{cheng2011global,achanta2009frequency,itti1998model}, which picks up visual attention parts from an image. However, prior salient region algorithms cannot satisfy the requirements due to their characteristics. The major constraints come from two aspects. First, to provide precise region boundaries, these prior algorithms generally include complex computation, which leads to slow processing speed. Second, a lot of local features locate on objects' edges and corners where are also the boundaries of salient regions. Therefore, precise salient region algorithms also means the feature points in the boundary would be discarded, which can decrease the retrieval accuracy.

To overcome these obstacles, we have a analysis on the relation between the salient region and the local features in an image. We found that the distribution of local features in salient regions is denser than outside regions, which we call salient features. Moreover, the feature points in the boundary of an object is important for accuracy. Based on these observations, we first design an approximate local feature-based salient region detection approach. It detects the salient regions through simple computing the distribution of local feature points. Due to no complex computation for precise boundary location, it is simple and fast. No precise boundary also guarantee feature points in the boundary are not discarded. Then, we implement a salient region conducted local feature-based algorithm. After detecting local feature points, salient regions are located immediately. And only the feature points in the regions will be described. Such a design can efficiently eliminate unimportant local features to accelerate processing speed and reduce storage requirement.  Experimental results show when compared to the original {\lfea}s, {\sys} achieves an overall 1.6X speedup with about 58\% storage reduction and 7\% accuracy loss.

In summary, this paper makes the following contributions:
\squishlist
\item An approximate salient region algorithm, which is efficient and accurate enough to be combined with {\lfea}s to accelerate the processing speed and reduce storage space.

\item A salient region conducted local feature algorithm that is 1.6X faster with only 42\% storage space requirement and 7\% accuracy loss.
\squishend

The rest of the paper is organized as follows. Section~\ref{sec:observation} presents the base motivation and observation for our algorithm. Section~\ref{sec:algorithm} discusses the details of the algorithm. Several evaluations are presented in Section~\ref{sec:evaluation}. We conclude the paper in Section~\ref{sec:conclusion}.
